{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eaca0d5",
   "metadata": {},
   "source": [
    "## MNIST handwritten digits prediction\n",
    "\n",
    "The MNIST (Modified National Institute of Standards and Technology) digits dataset is a widely used dataset in the field of machine learning and computer vision. It is commonly used for training and testing image processing systems, particularly in the context of handwritten digit recognition.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/800/1*LyRlX__08q40UJohhJG9Ow.png\" align=\"left\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74aed52",
   "metadata": {},
   "source": [
    "### Import Python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b54699b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/workspaces/python_machine_learning_basics/Neural_Networks\n"
     ]
    }
   ],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set TensorFlow log level to suppress warnings\n",
    "logging.disable(logging.WARNING)\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "# TensorFlow and Keras\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Show current working directory\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091c0d6c",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55992e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
      "X_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# The data, split between train and test sets\n",
    "(X_train, y_train), (X_test, y_test) = keras.datasets.mnist.load_data()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "X_train = X_train.astype(\"float32\") / 255\n",
    "X_test = X_test.astype(\"float32\") / 255\n",
    "\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "X_train = np.expand_dims(X_train, -1)\n",
    "X_test = np.expand_dims(X_test, -1)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(X_train.shape[0], \"train samples\")\n",
    "print(X_test.shape[0], \"test samples\")\n",
    "\n",
    "# Convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ba4128",
   "metadata": {},
   "source": [
    "### Show single handwritten digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4d0eb78d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 200x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show single digit image\n",
    "image  = X_train[2] # Change index in [] to show other digits\n",
    "fig    = plt.figure(figsize=(2,2))\n",
    "plt.imshow(image, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3b6f6af8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28, 28, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show shape of single digit image\n",
    "X_train[2].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a8a507e",
   "metadata": {},
   "source": [
    "### Initialize the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0c0cc3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear stack of layers\n",
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "        layers.Flatten(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2c1d03",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf93a33e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 43ms/step - accuracy: 0.8923 - loss: 0.3587 - val_accuracy: 0.9777 - val_loss: 0.0831\n",
      "Epoch 2/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 41ms/step - accuracy: 0.9663 - loss: 0.1104 - val_accuracy: 0.9855 - val_loss: 0.0569\n",
      "Epoch 3/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 38ms/step - accuracy: 0.9743 - loss: 0.0842 - val_accuracy: 0.9877 - val_loss: 0.0479\n",
      "Epoch 4/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 39ms/step - accuracy: 0.9777 - loss: 0.0712 - val_accuracy: 0.9895 - val_loss: 0.0409\n",
      "Epoch 5/5\n",
      "\u001b[1m422/422\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 39ms/step - accuracy: 0.9808 - loss: 0.0631 - val_accuracy: 0.9897 - val_loss: 0.0363\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x75fe4f7b1110>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define batch size and epochs\n",
    "batch_size = 128\n",
    "epochs = 5\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=\"categorical_crossentropy\", \n",
    "              optimizer=\"adam\", \n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, \n",
    "          y_train, \n",
    "          batch_size=batch_size, \n",
    "          epochs=epochs,\n",
    "          validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93da0e19",
   "metadata": {},
   "source": [
    "### Evaluate the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64229ad5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.0362\n",
      "Test accuracy: 0.9878\n"
     ]
    }
   ],
   "source": [
    "# Calculate the test loss and accuracy\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f\"Test loss: {score[0]:.4f}\")\n",
    "print(f\"Test accuracy: {score[1]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jupyter notebook --footer info-- (please always provide this at the end of each submitted notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------\n",
      "POSIX\n",
      "Linux | 6.8.0-1030-azure\n",
      "Datetime: 2025-11-03 07:12:02\n",
      "Python Version: 3.11.14\n",
      "-----------------------------------\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import platform\n",
    "import socket\n",
    "from platform import python_version\n",
    "from datetime import datetime\n",
    "\n",
    "print('-----------------------------------')\n",
    "print(os.name.upper())\n",
    "print(platform.system(), '|', platform.release())\n",
    "print('Datetime:', datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "print('Python Version:', python_version())\n",
    "print('-----------------------------------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
